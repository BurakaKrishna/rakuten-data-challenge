{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import gensim\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.externals import joblib\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('rdc-catalog-train.tsv',delimiter='\\t',encoding='utf-8',header=None)\n",
    "df.columns = ['text', 'label']\n",
    "\n",
    "#Isolate target data\n",
    "X = df[\"text\"].as_matrix().tolist()\n",
    "X = np.hstack(X)\n",
    "y = df[\"label\"].as_matrix().tolist()\n",
    "y = np.hstack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_full(classifier, X, y):\n",
    "    print(\"X:\")\n",
    "    print(len(X))\n",
    "    print(\"y:\")\n",
    "    print(len(y))\n",
    "    classifier.fit(X, y)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def train_test(classifier, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)\n",
    "    print(\"X_train:\")\n",
    "    print(len(X_train))\n",
    "    print(\"X_test:\")\n",
    "    print(len(X_test))\n",
    "    print(\"y_train:\")\n",
    "    print(len(y_train))\n",
    "    print(\"y_test:\")\n",
    "    print(len(y_test))\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(y_test,y_pred, pos_label=None, average='weighted')\n",
    "    print \"Accuracy: %s\" % classifier.score(X_test, y_test)\n",
    "    print \"Precision: %s\" % weighted_p\n",
    "    print \"Recall: %s\" % weighted_r\n",
    "    print \"F1-Score: %s\" % weighted_f1\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemming_tokenizer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]\n",
    "\n",
    "def lemmatization_tokenizer(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    return [wnl.lemmatize(w) for w in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "def standardize_metrics(text):\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(v|volt)\\b', 'metricV', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(amp|amps|ampere|amperes)\\b', 'metricA', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mah|ah|ampere-hour)\\b', 'metricAh', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(in|inch|inches)\\b', 'metricIn', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\\"', 'metricIn', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gb|gig|go|giga|gigabit|gigabyte)\\b', 'metricGb', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(oz|ounce)\\b', 'metricOz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fl\\.? oz\\.?|fluids? ounces?)\\b', 'metricFlOz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cwt|quintal)\\b', 'metricCwt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mhz|hz|khz|ghz|gigahertz|megahertz|kilohertz|hertz)\\b', 'metricHz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(wh|kwh|watt-hour|kilowatt-hour)\\b', 'metricWh', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(w|kw|watt|kilowatt)\\b', 'metricW', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mf|mfd|mmf|mmfd|microfarad)\\b', 'metricMfd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ft|feet|foot)\\b', 'metricFt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cm|centimeter)\\b', 'metricCm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mm|millimeter)\\b', 'metricMm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(km|kilometer)\\b', 'metricKm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(m|meter)\\b', 'metricM', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cell|cells)\\b', 'metricCell', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(lb|lbs|pound)\\b', 'metricLb', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yds|yd|yard|yards)\\b', 'metricYd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pc|pcs|pieces|piece)\\b', 'metricPc', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gal|gals|gallon|gallons)\\b', 'metricGal', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yd|yds|yard|yards)\\b', 'metricYd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(deg|degs|degree|degrees)\\b', 'metricDeg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\Â°', 'metricDeg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(l|liter|liters)\\b', 'metricL', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ml|mls|milliliter|milliliters)\\b', 'metricMl', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(kg|kilograms|kilogram)\\b', 'metricKg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(g|grams|gram)\\b', 'metricG', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mg|mgs|milligrams|milligram)\\b', 'metricMg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(sq|sqs|square|squares)\\b', 'metricSq', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pt|pts|pint|pints)\\b', 'metricPt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ohm)\\b', 'metricOhm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fz)\\b', 'metricFz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ct|cts|carat|carats)\\b', 'metricCt', text)\n",
    "    text = re.sub(r'\\b[\\d]+p\\b', 'metricRes', text)\n",
    "    text = re.sub(r'\\b[\\d]+x[\\d]+\\b', 'metricRes', text)\n",
    "    text = re.sub(r'\\b[\\d]+x\\b', 'metricX', text)\n",
    "    return text\n",
    "\n",
    "def clean_text_standard_metrics_v0plus(text):\n",
    "    text = text.lower()\n",
    "    text = standardize_metrics(text)\n",
    "    text = re.sub(r'\\b\\d*\\.\\d+\\b', 'nbDec', text)\n",
    "    text = re.sub(r'\\b\\d+\\/\\d+\\b', 'nbFra', text)\n",
    "    text = re.sub(r'\\b\\d+\\b', 'nbNat', text)\n",
    "#    text = re.sub(r'\\b(\\w*\\d\\w*[a-z]+\\w*|\\w*[a-z]+\\w*\\d\\w*)\\b', 'alphaNum', text)\n",
    "    text = re.sub('\\d+', '0', text) \n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "def clean_text_standardisation(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\bw\\/o','without ',text)\n",
    "    text = re.sub(r'\\bw\\/','with ',text)\n",
    "    text = re.sub(r'\\b(\\d+\\s?x\\s?)?\\d+(\\s|-|\\/|\\s?per\\s?|\\s?pc\\s?s\\/\\s?|)pa?cks?\\b', 'packUnit', text)\n",
    "    text = re.sub(r'\\b(\\d+\\s?x\\s?)?\\d+(\\s|-|\\/|\\s?per\\s?|\\s?pc\\s?s\\/\\s?|)sets?\\b', 'packUnit', text)\n",
    "    text = re.sub(r'\\bpa?cks?(\\s|-|\\sof\\s|)\\d+\\b', 'packUnit', text)\n",
    "    text = re.sub(r'\\bsets?(\\s|-|\\sof\\s|)\\d+\\b', 'packUnit', text)\n",
    "    text = standardize_metrics(text)\n",
    "#    text = re.sub(r'\\b\\d*\\.\\d+\\b', 'nbDec', text)\n",
    "#    text = re.sub(r'\\b\\d+\\/\\d+\\b', 'nbFra', text)\n",
    "#    text = re.sub(r'\\b\\d+\\b', 'nbNat', text)\n",
    "    text = re.sub('\\d+', '0', text) \n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X:\n",
      "800000\n",
      "y:\n",
      "800000\n",
      "[LibLinear]finished train\n"
     ]
    }
   ],
   "source": [
    "#TEST 26: lemmatization + clean_text_standardisation preprocessor + sublinear + single letter + min_df 2\n",
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 2), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,\n",
    "                                stop_words=single_letter+list(string.punctuation))),\n",
    "    ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_full(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>CategoryIdPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sterling Silver Dangle Ball Earrings w/ Brilli...</td>\n",
       "      <td>1608&gt;2320&gt;2173&gt;3813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disc Brake Rotor-Advanced Technology Rear Rayb...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coquette Neon Pink Ruffle Babydoll 7035 Neon P...</td>\n",
       "      <td>1608&gt;4269&gt;3031&gt;1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       CategoryIdPath\n",
       "0  Sterling Silver Dangle Ball Earrings w/ Brilli...  1608>2320>2173>3813\n",
       "1  ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...         2199>4592>12\n",
       "2  Disc Brake Rotor-Advanced Technology Rear Rayb...         2199>4592>12\n",
       "3  Coquette Neon Pink Ruffle Babydoll 7035 Neon P...  1608>4269>3031>1221\n",
       "4  12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...        3292>114>1231"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./rdc-catalog-test.tsv',delimiter='\\t',encoding='utf-8')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'2199>4592>12', u'2199>4592>12'], dtype='<U39')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(df.values[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['CategoryIdPath'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-834a0562db03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CategoryIdPath'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['CategoryIdPath'] not contained in axis"
     ]
    }
   ],
   "source": [
    "df = df.drop(['CategoryIdPath'],axis=1)\n",
    "df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sterling Silver Dangle Ball Earrings w/ Brilli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disc Brake Rotor-Advanced Technology Rear Rayb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coquette Neon Pink Ruffle Babydoll 7035 Neon P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title\n",
       "0  Sterling Silver Dangle Ball Earrings w/ Brilli...\n",
       "1  ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...\n",
       "2  Disc Brake Rotor-Advanced Technology Rear Rayb...\n",
       "3  Coquette Neon Pink Ruffle Babydoll 7035 Neon P...\n",
       "4  12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>CategoryIdPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sterling Silver Dangle Ball Earrings w/ Brilli...</td>\n",
       "      <td>1608&gt;2320&gt;2173&gt;2878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disc Brake Rotor-Advanced Technology Rear Rayb...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coquette Neon Pink Ruffle Babydoll 7035 Neon P...</td>\n",
       "      <td>1608&gt;4269&gt;3031&gt;1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       CategoryIdPath\n",
       "0  Sterling Silver Dangle Ball Earrings w/ Brilli...  1608>2320>2173>2878\n",
       "1  ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...         2199>4592>12\n",
       "2  Disc Brake Rotor-Advanced Technology Rear Rayb...         2199>4592>12\n",
       "3  Coquette Neon Pink Ruffle Babydoll 7035 Neon P...  1608>4269>3031>1221\n",
       "4  12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...        3292>114>1231"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values=np.hstack(df.values)\n",
    "predictions=clf.predict(values)\n",
    "df.insert(1,'CategoryIdPath',[pred for pred in predictions])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sterling Silver Dangle Ball Earrings w/ Brilli...</td>\n",
       "      <td>1608&gt;2320&gt;2173&gt;2878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disc Brake Rotor-Advanced Technology Rear Rayb...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coquette Neon Pink Ruffle Babydoll 7035 Neon P...</td>\n",
       "      <td>1608&gt;4269&gt;3031&gt;1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                    1\n",
       "0  Sterling Silver Dangle Ball Earrings w/ Brilli...  1608>2320>2173>2878\n",
       "1  ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...         2199>4592>12\n",
       "2  Disc Brake Rotor-Advanced Technology Rear Rayb...         2199>4592>12\n",
       "3  Coquette Neon Pink Ruffle Babydoll 7035 Neon P...  1608>4269>3031>1221\n",
       "4  12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...        3292>114>1231"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"submission_test_stdz2.tsv\", sep='\\t', encoding='utf-8',index=False,header=False)\n",
    "sub_df=pd.read_csv(\"submission_test_stdz2.tsv\",delimiter='\\t',encoding='utf-8',header=None)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X_train:\n",
      "600000\n",
      "X_test:\n",
      "200000\n",
      "y_train:\n",
      "600000\n",
      "y_test:\n",
      "200000\n",
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "#TEST 26: lemmatization + clean_text_standardisation preprocessor + sublinear + single letter + min_df 2 + tri gram\n",
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 3), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,\n",
    "                                stop_words=single_letter+list(string.punctuation))),\n",
    "    ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_test(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TEST 26: lemmatization + clean_text_standardisation preprocessor + sublinear + single letter + min_df 2 + quadri gram\n",
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 4), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,\n",
    "                                stop_words=single_letter+list(string.punctuation))),\n",
    "    ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_test(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TEST 26: lemmatization + clean_text_standardisation preprocessor + sublinear + single letter + min_df 2 + quadri gram\n",
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 5), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,\n",
    "                                stop_words=single_letter+list(string.punctuation))),\n",
    "    ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_test(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
