{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:14.098704Z",
     "start_time": "2018-06-22T08:14:09.457956Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import hstack\n",
    "import gensim\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.externals import joblib\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:19.353759Z",
     "start_time": "2018-06-22T08:14:14.100457Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('rdc-catalog-train.tsv',delimiter='\\t',encoding='utf-8',header=None)\n",
    "df.columns = ['text', 'label']\n",
    "\n",
    "#Isolate target data\n",
    "X = df[\"text\"].values\n",
    "X = np.hstack(X)\n",
    "y = df[\"label\"].values\n",
    "y = np.hstack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:19.360608Z",
     "start_time": "2018-06-22T08:14:19.356920Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_full(classifier, X, y):\n",
    "    print(\"X:\")\n",
    "    print(len(X))\n",
    "    print(\"y:\")\n",
    "    print(len(y))\n",
    "    classifier.fit(X, y)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def train_test(classifier, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)\n",
    "    print(\"X_train:\")\n",
    "    print(len(X_train))\n",
    "    print(\"X_test:\")\n",
    "    print(len(X_test))\n",
    "    print(\"y_train:\")\n",
    "    print(len(y_train))\n",
    "    print(\"y_test:\")\n",
    "    print(len(y_test))\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(y_test,y_pred, pos_label=None, average='weighted')\n",
    "    print(\"Accuracy: \", classifier.score(X_test, y_test))\n",
    "    print(\"Precision: \", weighted_p)\n",
    "    print(\"Recall: \", weighted_r)\n",
    "    print(\"F1-Score: \", weighted_f1)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:19.477954Z",
     "start_time": "2018-06-22T08:14:19.361810Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemming_tokenizer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]\n",
    "\n",
    "def lemmatization_tokenizer(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    return [wnl.lemmatize(w) for w in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:19.532522Z",
     "start_time": "2018-06-22T08:14:19.481287Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize_metrics(text):\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(v|volt)\\b', 'metricV', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(amp|amps|ampere|amperes)\\b', 'metricA', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mah|ah|ampere-hour)\\b', 'metricAh', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(in|inch|inches)\\b', 'metricIn', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\\"', 'metricIn', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gb|gig|go|giga|gigabit|gigabyte)\\b', 'metricGb', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(oz|ounce)\\b', 'metricOz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fl\\.? oz\\.?|fluids? ounces?)\\b', 'metricFlOz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cwt|quintal)\\b', 'metricCwt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mhz|hz|khz|ghz|gigahertz|megahertz|kilohertz|hertz)\\b', 'metricHz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(wh|kwh|watt-hour|kilowatt-hour)\\b', 'metricWh', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(w|kw|watt|kilowatt)\\b', 'metricW', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mf|mfd|mmf|mmfd|microfarad)\\b', 'metricMfd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ft|feet|foot)\\b', 'metricFt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cm|centimeter)\\b', 'metricCm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mm|millimeter)\\b', 'metricMm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(km|kilometer)\\b', 'metricKm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(m|meter)\\b', 'metricM', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cell|cells)\\b', 'metricCell', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(lb|lbs|pound)\\b', 'metricLb', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yds|yd|yard|yards)\\b', 'metricYd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pc|pcs|pieces|piece)\\b', 'metricPc', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gal|gals|gallon|gallons)\\b', 'metricGal', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yd|yds|yard|yards)\\b', 'metricYd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(deg|degs|degree|degrees)\\b', 'metricDeg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\Â°', 'metricDeg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(l|liter|liters)\\b', 'metricL', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ml|mls|milliliter|milliliters)\\b', 'metricMl', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(kg|kilograms|kilogram)\\b', 'metricKg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(g|grams|gram)\\b', 'metricG', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mg|mgs|milligrams|milligram)\\b', 'metricMg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(sq|sqs|square|squares)\\b', 'metricSq', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pt|pts|pint|pints)\\b', 'metricPt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ohm)\\b', 'metricOhm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fz)\\b', 'metricFz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ct|cts|carat|carats)\\b', 'metricCt', text)\n",
    "    text = re.sub(r'\\b[\\d]+p\\b', 'metricRes', text)\n",
    "    text = re.sub(r'\\b[\\d]+x[\\d]+\\b', 'metricRes', text)\n",
    "    text = re.sub(r'\\b[\\d]+x\\b', 'metricX', text)\n",
    "    return text\n",
    "\n",
    "def clean_text_standard_metrics_v0plus(text):\n",
    "    text = text.lower()\n",
    "    text = standardize_metrics(text)\n",
    "    text = re.sub(r'\\b\\d*\\.\\d+\\b', 'nbDec', text)\n",
    "    text = re.sub(r'\\b\\d+\\/\\d+\\b', 'nbFra', text)\n",
    "    text = re.sub(r'\\b\\d+\\b', 'nbNat', text)\n",
    "    text = re.sub('\\d+', '0', text) \n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "def standardize_char(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\b(\\d+\\s?x\\s?)?\\d+(\\s|-|\\/|\\s?per\\s?|\\s?pc\\s?s\\/\\s?|)pa?cks?\\b', 'pck', text)\n",
    "    text = re.sub(r'\\bpa?cks?(\\s|-|\\sof\\s|)\\d+\\b', 'pck', text)\n",
    "    text = re.sub(r'\\b(\\d+\\s?x\\s?)?\\d+(\\s|-|\\/|\\s?per\\s?|\\s?pc\\s?s\\/\\s?|)sets?\\b', 'set', text)\n",
    "    text = re.sub(r'\\bsets?(\\s|-|\\sof\\s|)\\d+\\b', 'set', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(v|volt)\\b', 'v', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(amp|amps|ampere|amperes)\\b', 'a', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mah|ah|ampere-hour)\\b', 'ah', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(in|inch|inches)\\b', 'in', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\\"', 'in', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gb|gig|go|giga|gigabit|gigabyte)\\b', 'gb', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(oz|ounce)\\b', 'oz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fl\\.? oz\\.?|fluids? ounces?)\\b', 'floz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cwt|quintal)\\b', 'cwt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mhz|hz|khz|ghz|gigahertz|megahertz|kilohertz|hertz)\\b', 'hz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(wh|kwh|watt-hour|kilowatt-hour)\\b', 'wh', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(w|kw|watt|kilowatt)\\b', 'w', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mf|mfd|mmf|mmfd|microfarad)\\b', 'mfd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ft|feet|foot)\\b', 'ft', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cm|centimeter)\\b', 'cm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mm|millimeter)\\b', 'mm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(km|kilometer)\\b', 'km', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(m|meter)\\b', 'm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cell|cells)\\b', 'cell', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(lb|lbs|pound)\\b', 'lb', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yds|yd|yard|yards)\\b', 'yd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pc|pcs|pieces|piece)\\b', 'pcs', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gal|gals|gallon|gallons)\\b', 'gal', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yd|yds|yard|yards)\\b', 'yd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(deg|degs|degree|degrees)\\b', 'deg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\Â°', 'deg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(l|liter|liters)\\b', 'l', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ml|mls|milliliter|milliliters)\\b', 'ml', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(kg|kilograms|kilogram)\\b', 'kg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(g|grams|gram)\\b', 'g', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mg|mgs|milligrams|milligram)\\b', 'mg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(sq|sqs|square|squares)\\b', 'sg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pt|pts|pint|pints)\\b', 'pt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ohm)\\b', 'ohm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fz)\\b', 'fz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ct|cts|carat|carats)\\b', 'ct', text)\n",
    "    text = re.sub(r'\\b[\\d]+p\\b', 'res', text)\n",
    "    text = re.sub(r'\\b[\\d]+x[\\d]+\\b', 'res', text)\n",
    "    text = re.sub(r'\\b[\\d]+x\\b', 'x', text)\n",
    "    text = re.sub(r'\\b\\d*\\.\\d+\\b', 'deci', text)\n",
    "    text = re.sub(r'\\b\\d+\\/\\d+\\b', 'frac', text)\n",
    "    text = re.sub(r'\\b\\d+\\b', 'nat', text)\n",
    "    text = re.sub(r'\\b(\\w*\\d\\w*[a-z]+\\w*|\\w*[a-z]+\\w*\\d\\w*)\\b', 'sku', text)\n",
    "    text = re.sub('\\d+', '0', text) \n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "def xtrem_clean_char(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\b(\\d+\\s?x\\s?)?\\d+(\\s|-|\\/|\\s?per\\s?|\\s?pc\\s?s\\/\\s?|)pa?cks?\\b', '', text)\n",
    "    text = re.sub(r'\\bpa?cks?(\\s|-|\\sof\\s|)\\d+\\b', '', text)\n",
    "    text = re.sub(r'\\b(\\d+\\s?x\\s?)?\\d+(\\s|-|\\/|\\s?per\\s?|\\s?pc\\s?s\\/\\s?|)sets?\\b', '', text)\n",
    "    text = re.sub(r'\\bsets?(\\s|-|\\sof\\s|)\\d+\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(v|volt)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(amp|amps|ampere|amperes)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mah|ah|ampere-hour)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(in|inch|inches)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\\"', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gb|gig|go|giga|gigabit|gigabyte)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(oz|ounce)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fl\\.? oz\\.?|fluids? ounces?)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cwt|quintal)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mhz|hz|khz|ghz|gigahertz|megahertz|kilohertz|hertz)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(wh|kwh|watt-hour|kilowatt-hour)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(w|kw|watt|kilowatt)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mf|mfd|mmf|mmfd|microfarad)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ft|feet|foot)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cm|centimeter)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mm|millimeter)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(km|kilometer)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(m|meter)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cell|cells)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(lb|lbs|pound)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yds|yd|yard|yards)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pc|pcs|pieces|piece)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gal|gals|gallon|gallons)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yd|yds|yard|yards)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(deg|degs|degree|degrees)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\Â°', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(l|liter|liters)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ml|mls|milliliter|milliliters)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(kg|kilograms|kilogram)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(g|grams|gram)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mg|mgs|milligrams|milligram)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(sq|sqs|square|squares)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pt|pts|pint|pints)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ohm)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fz)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ct|cts|carat|carats)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d]+p\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d]+x[\\d]+\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d]+x\\b', '', text)\n",
    "    text = re.sub(r'\\b\\d*\\.\\d+\\b', '', text)\n",
    "    text = re.sub(r'\\b\\d+\\/\\d+\\b', '', text)\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    text = re.sub(r'\\b(\\w*\\d\\w*[a-z]+\\w*|\\w*[a-z]+\\w*\\d\\w*)\\b', '', text)\n",
    "    text = re.sub('\\d+', '', text) \n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X_train:\n",
      "600000\n",
      "X_test:\n",
      "200000\n",
      "y_train:\n",
      "600000\n",
      "y_test:\n",
      "200000\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.817935\n",
      "Precision: 0.8095020763184998\n",
      "Recall: 0.817935\n",
      "F1-Score: 0.8100457644640601\n",
      "finished train\n"
     ]
    }
   ],
   "source": [
    "#TEST 26: lemmatization + clean_text_standard_metrics_v0plus preprocessor + sublinear + single letter + min_df 2\n",
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 2), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,\n",
    "                                stop_words=single_letter+list(string.punctuation))),\n",
    "    ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_test(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X_train:\n",
      "600000\n",
      "X_test:\n",
      "200000\n",
      "y_train:\n",
      "600000\n",
      "y_test:\n",
      "200000\n",
      "[LibLinear]Accuracy: 0.820155\n",
      "Precision: 0.8108338638615838\n",
      "Recall: 0.820155\n",
      "F1-Score: 0.8108139486508633\n",
      "finished train\n"
     ]
    }
   ],
   "source": [
    "#TEST 28b: char n gram\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=2,norm='l2', ngram_range=(1,4),lowercase=True, analyzer='char',strip_accents='unicode')),\n",
    "    ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_test(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T15:21:19.907855Z",
     "start_time": "2018-06-19T12:10:03.071977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X_train:\n",
      "600000\n",
      "X_test:\n",
      "200000\n",
      "y_train:\n",
      "600000\n",
      "y_test:\n",
      "200000\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.819765\n",
      "Precision:  0.810456071770931\n",
      "Recall:  0.819765\n",
      "F1-Score:  0.810496372763874\n",
      "finished train\n"
     ]
    }
   ],
   "source": [
    "#TEST 40: char n gram (limited features to 250k)\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=2,norm='l2', ngram_range=(1,4),lowercase=True, analyzer='char',strip_accents='unicode',max_features=250000)),\n",
    "    ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_test(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T19:46:38.802735Z",
     "start_time": "2018-06-19T16:50:30.229637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X_train:\n",
      "600000\n",
      "X_test:\n",
      "200000\n",
      "y_train:\n",
      "600000\n",
      "y_test:\n",
      "200000\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.828935\n",
      "Precision:  0.8224192086402817\n",
      "Recall:  0.828935\n",
      "F1-Score:  0.822521044388522\n",
      "finished train\n"
     ]
    }
   ],
   "source": [
    "#TEST 41: word/char limit to 600k features\n",
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "max_features = 600000\n",
    "clf = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('characters', Pipeline([\n",
    "      ('char_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,norm='l2', ngram_range=(1,4),lowercase=True, analyzer='char',strip_accents='unicode',max_features=int(max_features/2)))\n",
    "    ])),\n",
    "    ('words', Pipeline([\n",
    "      ('words_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 2), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,stop_words=single_letter+list(string.punctuation),max_features=int(max_features/2)))\n",
    "    ])),\n",
    "  ])),\n",
    "  ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_test(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:28:57.103239Z",
     "start_time": "2018-06-19T20:27:50.023914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X_train:\n",
      "600000\n",
      "X_test:\n",
      "200000\n",
      "y_train:\n",
      "600000\n",
      "y_test:\n",
      "200000\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.829165\n",
      "Precision:  0.8226888384508295\n",
      "Recall:  0.829165\n",
      "F1-Score:  0.822767246106143\n",
      "finished train\n"
     ]
    }
   ],
   "source": [
    "#TEST 42: word/char limit to 700k features\n",
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "max_features = 700000\n",
    "clf = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('characters', Pipeline([\n",
    "      ('char_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,norm='l2', ngram_range=(1,4),lowercase=True, analyzer='char',strip_accents='unicode',max_features=int(max_features/2)))\n",
    "    ])),\n",
    "    ('words', Pipeline([\n",
    "      ('words_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 2), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,stop_words=single_letter+list(string.punctuation),max_features=int(max_features/2)))\n",
    "    ])),\n",
    "  ])),\n",
    "  ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_test(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:30:36.130135Z",
     "start_time": "2018-06-19T23:28:57.104587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/rakutenWordCharTest.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, '/home/rakutenWordCharTest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T15:40:05.356574Z",
     "start_time": "2018-06-20T12:17:46.225053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X:\n",
      "800000\n",
      "y:\n",
      "800000\n",
      "[LibLinear]finished train\n"
     ]
    }
   ],
   "source": [
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "max_features = 700000\n",
    "clf = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('characters', Pipeline([\n",
    "      ('char_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,norm='l2', ngram_range=(1,4),lowercase=True, analyzer='char',strip_accents='unicode',max_features=int(max_features/2)))\n",
    "    ])),\n",
    "    ('words', Pipeline([\n",
    "      ('words_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 2), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,stop_words=single_letter+list(string.punctuation),max_features=int(max_features/2)))\n",
    "    ])),\n",
    "  ])),\n",
    "  ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_full(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T15:41:22.647819Z",
     "start_time": "2018-06-20T15:40:05.359319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/rakutenWordCharFull.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, '/home/rakutenWordCharFull.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T15:41:38.637965Z",
     "start_time": "2018-06-20T15:41:22.649265Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = joblib.load('/home/rakutenWordCharFull.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T15:59:10.557974Z",
     "start_time": "2018-06-21T15:59:10.120052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>CategoryIdPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sterling Silver Dangle Ball Earrings w/ Brilli...</td>\n",
       "      <td>1608&gt;2320&gt;2173&gt;3813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disc Brake Rotor-Advanced Technology Rear Rayb...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coquette Neon Pink Ruffle Babydoll 7035 Neon P...</td>\n",
       "      <td>1608&gt;4269&gt;3031&gt;1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       CategoryIdPath\n",
       "0  Sterling Silver Dangle Ball Earrings w/ Brilli...  1608>2320>2173>3813\n",
       "1  ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...         2199>4592>12\n",
       "2  Disc Brake Rotor-Advanced Technology Rear Rayb...         2199>4592>12\n",
       "3  Coquette Neon Pink Ruffle Babydoll 7035 Neon P...  1608>4269>3031>1221\n",
       "4  12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...        3292>114>1231"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./rdc-catalog-test.tsv',delimiter='\\t',encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T15:59:11.330118Z",
     "start_time": "2018-06-21T15:59:11.324535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T18:39:28.496490Z",
     "start_time": "2018-06-20T18:39:28.488525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T15:59:17.210167Z",
     "start_time": "2018-06-21T15:59:17.190770Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-29f793043f69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CategoryIdPath'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CategoryIdPath'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['CategoryIdPath'])\n",
    "df.insert(1,'CategoryIdPath',[pred for pred in predictions])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T18:41:26.182275Z",
     "start_time": "2018-06-20T18:41:25.619241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sterling Silver Dangle Ball Earrings w/ Brilli...</td>\n",
       "      <td>1608&gt;2320&gt;2173&gt;2878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disc Brake Rotor-Advanced Technology Rear Rayb...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coquette Neon Pink Ruffle Babydoll 7035 Neon P...</td>\n",
       "      <td>1608&gt;4269&gt;3031&gt;1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                    1\n",
       "0  Sterling Silver Dangle Ball Earrings w/ Brilli...  1608>2320>2173>2878\n",
       "1  ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...         2199>4592>12\n",
       "2  Disc Brake Rotor-Advanced Technology Rear Rayb...         2199>4592>12\n",
       "3  Coquette Neon Pink Ruffle Babydoll 7035 Neon P...  1608>4269>3031>1221\n",
       "4  12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...        3292>114>1231"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"submission_test_combined.tsv\", sep='\\t', encoding='utf-8',index=False,header=False)\n",
    "sub_df=pd.read_csv(\"submission_test_combined.tsv\",delimiter='\\t',encoding='utf-8',header=None)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T15:59:22.294492Z",
     "start_time": "2018-06-21T15:59:22.289704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:29.050793Z",
     "start_time": "2018-06-22T08:14:28.779654Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "c = collections.Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:31.219794Z",
     "start_time": "2018-06-22T08:14:30.401704Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('rdc-catalog-train.tsv',delimiter='\\t',encoding='utf-8',header=None)\n",
    "df.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:31.621300Z",
     "start_time": "2018-06-22T08:14:31.615595Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_single = c.most_common()[:-20:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:35.156008Z",
     "start_time": "2018-06-22T08:14:33.793473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2075>3671>4896>3337\n",
      "4015>2824>2964>2473>4559>1399>2913\n",
      "3292>2790>1053>2721\n",
      "2199>1952>3163>1822\n",
      "3730>2720>4005>2321\n",
      "4238>2371>1833>113\n",
      "4238>321>777>4022\n",
      "3625>3608>971\n",
      "3730>1439>4712>3507\n",
      "4564>802>3059>2754\n",
      "1395>2736>4447>2048>3707\n",
      "3730>1874>2009>2992\n",
      "4015>2028>3803>2617\n",
      "2199>2819>4536\n",
      "1395>2736>3899>2657>4591\n",
      "2075>1724>3258>1372>3689\n",
      "3292>2375>1365>1640\n",
      "2075>3407>2214>2828\n",
      "2199>661>909>1069\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df\n",
    "for (y_to_delete,_) in y_single:\n",
    "    df_filtered = df_filtered.ix[~(df['label'] == y_to_delete)]\n",
    "    print(y_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:43.186694Z",
     "start_time": "2018-06-22T08:14:43.179329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799981, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:47.749341Z",
     "start_time": "2018-06-22T08:14:43.761859Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Isolate target data\n",
    "df = df_filtered\n",
    "X = df[\"text\"].values\n",
    "X = np.hstack(X)\n",
    "y = df[\"label\"].values\n",
    "y = np.hstack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:48.124981Z",
     "start_time": "2018-06-22T08:14:47.751239Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:48.317848Z",
     "start_time": "2018-06-22T08:14:48.126211Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = collections.Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:14:51.233652Z",
     "start_time": "2018-06-22T08:14:51.227895Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_single = c.most_common()[:-52:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:15:07.217033Z",
     "start_time": "2018-06-22T08:14:54.429299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3625>3641>2412>363\n",
      "1395>2736>4446>1799>3413\n",
      "4015>3285>345>1585>3448\n",
      "1608>2227>574>2130\n",
      "3625>3641>3549>3028\n",
      "4015>2824>2964>2473>839>2732>1977\n",
      "3292>2375>4400>3342\n",
      "2199>661>4818>3006\n",
      "3292>3581>2023\n",
      "4015>3754>3580>4753>3650>4100\n",
      "2075>1724>579>2385>1981\n",
      "4015>2824>2964>2473>839>2966>1930\n",
      "4015>870>4606>254\n",
      "3292>290>580>2908\n",
      "1395>410>2503>528>991\n",
      "3292>3581>1878>1337\n",
      "2199>661>4818>4309\n",
      "3730>1439>4557\n",
      "1395>2736>135>4873>941\n",
      "2075>2267>2180>508\n",
      "4015>4868>3880\n",
      "4015>3754>3663>512>2406>533\n",
      "4015>3285>345>483>2923\n",
      "3625>3641>1599>3116\n",
      "3093>4104>3495\n",
      "2075>3671>956>907>1303\n",
      "1395>2736>4446>4316>4789\n",
      "4015>2824>2964>32>2341>1029\n",
      "2075>3671>700>4621\n",
      "4564>1265>26>4465>4897\n",
      "3730>2720>1864>1838\n",
      "4015>2337>2943>2570>2866\n",
      "4015>2824>567>1982\n",
      "4238>1625>3571>2034\n",
      "4015>2824>2964>2473>839>2966>4511\n",
      "3625>3641>1599>822\n",
      "3730>2720>1836>2581\n",
      "2075>3671>2703>3684\n",
      "3730>1439>805>4129\n",
      "3625>3641>2998>2294\n",
      "1395>410>474>105>8\n",
      "4238>321>753>4424\n",
      "2075>3407>2214>605\n",
      "3625>381>622\n",
      "2075>3671>396>4126\n",
      "4015>2824>2964>2886>4183>1530>1904\n",
      "4015>2824>2964>2473>4559>1399>1188\n",
      "2199>915>4085>1503\n",
      "3625>3641>3045>4608\n",
      "1395>2736>3899>3790>3501\n",
      "4564>1265>1706>1158>4321\n"
     ]
    }
   ],
   "source": [
    "X_train_filtered = X_train\n",
    "y_train_filtered = y_train\n",
    "for (y_to_delete,_) in y_single:\n",
    "    index, = np.where(y_train_filtered == y_to_delete)\n",
    "    y_train_filtered = np.delete(y_train_filtered, index)\n",
    "    X_train_filtered = np.delete(X_train_filtered, index)\n",
    "    print(y_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:15:07.221010Z",
     "start_time": "2018-06-22T08:15:07.218405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(599934,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T08:15:07.305067Z",
     "start_time": "2018-06-22T08:15:07.221968Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ReShaper(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vars = [] \n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.reshape(-1,)  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T11:38:03.385643Z",
     "start_time": "2018-06-22T11:38:03.377103Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "max_features = 400000\n",
    "clf = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('characters', Pipeline([\n",
    "      ('char_reshape', ReShaper()),\n",
    "      ('char_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,norm='l2', ngram_range=(1,4),lowercase=True, analyzer='char',strip_accents='unicode',max_features=int(max_features/2)))\n",
    "    ])),\n",
    "    ('words', Pipeline([\n",
    "      ('char_reshape', ReShaper()),\n",
    "      ('words_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 2), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,stop_words=single_letter+list(string.punctuation),max_features=int(max_features/2)))\n",
    "    ])),\n",
    "  ],n_jobs=2)),\n",
    "  ('classifier', LinearSVC(verbose=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T13:56:55.639823Z",
     "start_time": "2018-06-22T11:38:04.709733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=2,\n",
       "       transformer_list=[('characters', Pipeline(memory=None,\n",
       "     steps=[('char_reshape', ReShaper()), ('char_tf_idf', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='conte...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=1))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_filtered.reshape(-1,1), y_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T13:57:56.577831Z",
     "start_time": "2018-06-22T13:56:55.641331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/rakutenPrefitTest.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, '/home/rakutenPrefitTest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T13:57:56.776607Z",
     "start_time": "2018-06-22T13:57:56.581986Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f527d3e38b19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mweighted_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1-Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_f1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    766\u001b[0m         Xs = Parallel(n_jobs=self.n_jobs)(\n\u001b[1;32m    767\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             for name, trans, weight in self._iter())\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;31m# All transformers are None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_effective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_initialize_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n\u001b[0;32m--> 547\u001b[0;31m                                              **self._backend_args)\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_timeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 warnings.warn(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mconfigure\u001b[0;34m(self, n_jobs, parallel, **backend_args)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# Make sure to free as much memory as possible before forking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMemmapingPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbackend_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, temp_folder, max_nbytes, mmap_mode, forward_reducers, backward_reducers, verbose, context_id, prewarm, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m             backward_reducers=backward_reducers)\n\u001b[1;32m    599\u001b[0m         \u001b[0mpoolargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMemmapingPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpoolargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, forward_reducers, backward_reducers, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mpoolargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mpoolargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPicklingPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpoolargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_queues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repopulate_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         self._worker_handler = threading.Thread(\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_repopulate_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PoolWorker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'added worker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test.reshape(-1,1))\n",
    "weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(y_test,y_pred, pos_label=None, average='weighted')\n",
    "print(\"Precision:\", weighted_p)\n",
    "print(\"Recall:\", weighted_r)\n",
    "print(\"F1-Score:\", weighted_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T13:57:56.777496Z",
     "start_time": "2018-06-22T11:38:30.998Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = CalibratedClassifierCV(clf, cv='prefit',method='isotonic')\n",
    "model.fit(X_train_filtered.reshape(-1,1), y_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T13:57:56.778374Z",
     "start_time": "2018-06-22T11:38:31.641Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T13:57:56.779306Z",
     "start_time": "2018-06-22T11:38:52.229Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test.reshape(-1,1))\n",
    "weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(y_test,y_pred, pos_label=None, average='weighted')\n",
    "print(\"Precision:\", weighted_p)\n",
    "print(\"Recall:\", weighted_r)\n",
    "print(\"F1-Score:\", weighted_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
